# -*- coding: utf-8 -*-
"""activation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SPvFEytIWexO9zfnAt-UFSpfwqkzmLVN
"""

import numpy as np
import matplotlib.pyplot as plt

x = np.linspace(-5, 5, 100)
plt.plot(x, 1 / (1 + np.exp(-x)), label='Sigmoid')
plt.plot(x, np.tanh(x), label='tanh')
plt.plot(x, np.maximum(0, x), label='ReLU')
plt.plot(x, x, label='Identity')
plt.plot(x, np.exp(x) / np.sum(np.exp(x)), label='Softmax')

plt.xlabel('Input')
plt.ylabel('Activation')
plt.title('Activation Functions')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def relu(x):
    return np.maximum(0, x)

def tanh(x):
    return np.tanh(x)

def leaky_relu(x, alpha=0.01):
    return np.where(x > 0, x, alpha * x)

def plot_activation_functions():
    x = np.linspace(-5, 5, 100)

    plt.figure(figsize=(12, 8))

    plt.subplot(2, 2, 1)
    plt.plot(x, sigmoid(x), label='Sigmoid')
    plt.title('Sigmoid Activation Function')
    plt.legend()

    plt.subplot(2, 2, 2)
    plt.plot(x, relu(x), label='ReLU')
    plt.title('ReLU Activation Function')
    plt.legend()

    plt.subplot(2, 2, 3)
    plt.plot(x, tanh(x), label='Tanh')
    plt.title('Tanh Activation Function')
    plt.legend()

    plt.subplot(2, 2, 4)
    plt.plot(x, np.exp(x) / np.sum(np.exp(x)), label='Softmax')
    plt.title('Leaky ReLU Activation Function')
    plt.legend()

    plt.tight_layout()
    plt.show()

plot_activation_functions()

